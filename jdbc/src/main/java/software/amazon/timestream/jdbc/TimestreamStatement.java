/*
 * Copyright <2020> Amazon.com, Inc. or its affiliates. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License").
 * You may not use this file except in compliance with the License.
 * A copy of the License is located at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * or in the "license" file accompanying this file. This file is distributed
 * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
 * express or implied. See the License for the specific language governing
 * permissions and limitations under the License.
 */

package software.amazon.timestream.jdbc;

import com.amazonaws.ClientConfiguration;
import com.amazonaws.http.timers.client.ClientExecutionTimeoutException;
import com.amazonaws.services.timestreamquery.AmazonTimestreamQuery;
import com.amazonaws.services.timestreamquery.model.AmazonTimestreamQueryException;
import com.amazonaws.services.timestreamquery.model.CancelQueryRequest;
import com.amazonaws.services.timestreamquery.model.ConflictException;
import com.amazonaws.services.timestreamquery.model.QueryRequest;
import com.amazonaws.services.timestreamquery.model.QueryResult;
import com.amazonaws.services.timestreamquery.model.Row;
import com.google.common.annotations.VisibleForTesting;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.sql.ResultSet;
import java.sql.SQLException;
import java.sql.SQLFeatureNotSupportedException;
import java.sql.SQLTimeoutException;
import java.sql.SQLWarning;
import java.sql.Statement;
import java.util.List;
import java.util.Map;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.atomic.AtomicReference;

/**
 * Timestream implementation of {@link Statement}.
 */
public class TimestreamStatement implements java.sql.Statement {
  private static final Logger LOGGER = LoggerFactory.getLogger(TimestreamStatement.class);

  private final TimestreamConnection connection;
  private final Map<String, Class<?>> typeMap;
  private final AtomicBoolean isClosed = new AtomicBoolean(false);
  private final ClientConfiguration clientConfiguration;
  private final AtomicLong totalExecutionTime = new AtomicLong();
  private int maxFieldSize = 0;
  private long largeMaxRows = 0;
  private final AtomicReference<String> queryId = new AtomicReference<>(null);
  private final AtomicInteger numEmptyPages = new AtomicInteger();
  private final AtomicInteger numPages = new AtomicInteger();
  private boolean shouldCloseOnCompletion = false;
  private SQLWarning warnings;
  private int fetchSize = 0;
  private ResultSet resultSet;
  private AmazonTimestreamQuery queryClient;

  @VisibleForTesting
  final AtomicBoolean canCancel = new AtomicBoolean(false);

  /**
   * Constructor for seeding the statement with the parent connection.
   *
   * @param connection The parent connection.
   * @throws SQLException if error occurs when get type map of connection.
   */
  TimestreamStatement(TimestreamConnection connection) throws SQLException {
    this.connection = connection;
    this.warnings = null;
    this.typeMap = connection.getTypeMap();
    this.clientConfiguration = new ClientConfiguration(
        connection.getQueryClientBuilder().getClientConfiguration());
    this.queryClient = connection.getQueryClientBuilder()
        .withClientConfiguration(this.clientConfiguration)
        .build();
  }

  @Override
  public void addBatch(String sql) throws SQLException {
    verifyOpen();
    throw new SQLFeatureNotSupportedException();
  }

  @Override
  public void cancel() throws SQLException {
    verifyOpen();
    doCancel();
  }

  @Override
  public void clearBatch() throws SQLException {
    verifyOpen();
    throw new SQLFeatureNotSupportedException();
  }

  @Override
  public void clearWarnings() throws SQLException {
    verifyOpen();
    warnings = null;
  }

  @Override
  public void close() throws SQLException {
    if (!this.isClosed.getAndSet(true)) {
      LOGGER.debug("Cancel any running queries.");
      doCancel();

      if (this.resultSet != null) {
        LOGGER.debug("Close opened result set.");
        this.resultSet.close();
      }
    }
  }

  @Override
  public void closeOnCompletion() throws SQLException {
    verifyOpen();
    this.shouldCloseOnCompletion = true;
  }

  @Override
  public boolean execute(String sql) throws SQLException {
    this.resultSet = executeQuery(sql);
    return true;
  }

  @Override
  public boolean execute(String sql, int autoGeneratedKeys) throws SQLException {
    // Ignore the auto-generated keys as INSERT is not supported and auto-generated keys are not supported.
    return execute(sql);
  }

  @Override
  public boolean execute(String sql, int[] columnIndexes) throws SQLException {
    // Ignore the auto-generated keys as INSERT is not supported and auto-generated keys are not supported.
    return execute(sql);
  }

  @Override
  public boolean execute(String sql, String[] columnNames) throws SQLException {
    // Ignore the auto-generated keys as INSERT is not supported and auto-generated keys are not supported.
    return execute(sql);
  }

  @Override
  public int[] executeBatch() throws SQLException {
    verifyOpen();
    throw new SQLFeatureNotSupportedException();
  }

  @Override
  public long[] executeLargeBatch() throws SQLException {
    verifyOpen();
    throw new SQLFeatureNotSupportedException();
  }

  @Override
  public long executeLargeUpdate(String sql) throws SQLException {
    verifyOpen();
    throw new SQLFeatureNotSupportedException(Error.lookup(Error.READ_ONLY));
  }

  @Override
  public long executeLargeUpdate(String sql, int autoGeneratedKeys) throws SQLException {
    verifyOpen();
    throw new SQLFeatureNotSupportedException(Error.lookup(Error.READ_ONLY));
  }

  @Override
  public long executeLargeUpdate(String sql, int[] columnIndexes) throws SQLException {
    verifyOpen();
    throw new SQLFeatureNotSupportedException(Error.lookup(Error.READ_ONLY));
  }

  @Override
  public long executeLargeUpdate(String sql, String[] columnNames) throws SQLException {
    verifyOpen();
    throw new SQLFeatureNotSupportedException(Error.lookup(Error.READ_ONLY));
  }

  @Override
  public synchronized ResultSet executeQuery(final String sql) throws SQLException {
    verifyOpen();

    if (this.resultSet != null) {
      this.resultSet.close();
    }

    final QueryRequest request = new QueryRequest().withQueryString(sql);

    final int queryFetchSize = this.getFetchSize();
    if (queryFetchSize != 0) {
      request.withMaxRows(queryFetchSize);
    }

    QueryResult result;
    try {
      try {
        result = retrieveResult(request);
        this.queryId.set(result.getQueryId());
        LOGGER.info("Query ID: {}", this.queryId);
        this.canCancel.set(true);
        List<Row> rows = result.getRows();
        String nextToken = result.getNextToken();
        while ((rows.size() == 0) && (nextToken != null)) {
          this.numEmptyPages.incrementAndGet();
          if (isClosed.get()) {
            doCancel();
            throw Error.createSQLException(
              LOGGER,
              Error.STMT_CLOSED_DURING_EXECUTE,
              this.queryId.get());
          }

          try {
            result = retrieveResult(request.withNextToken(nextToken));
            rows = result.getRows();
            nextToken = result.getNextToken();
          } catch (final ConflictException conflictException) {
            // ConflictException is thrown when attempting to retrieve more rows on a
            // query that has been canceled.
            throw Error.createSQLException(
              LOGGER,
              Constants.OPERATION_CANCELED_SQL_STATE,
              conflictException,
              Error.QUERY_CANCELED,
              this.queryId.get());
          }
        }
      } finally {
        this.canCancel.set(false);
      }

      this.resultSet = new TimestreamResultSet(
        this,
        sql,
        result,
        this.typeMap,
        this.largeMaxRows,
        this.maxFieldSize,
        this.totalExecutionTime.get(),
        this.numPages.get());
      LOGGER.info(
        "Query ID: {}\n"
          + "Time to first result: {}ms\n"
          + "Total number of pages: {}\n"
          + "Number of empty pages: {}\n"
          + "Number of rows: {}",
        this.queryId,
        this.totalExecutionTime,
        this.numPages,
        this.numEmptyPages,
        result.getRows().size());
      return resultSet;
    } catch (final AmazonTimestreamQueryException e) {
      throw Error.createSQLException(
        LOGGER,
        e,
        Error.INVALID_QUERY,
        this.queryId.get(),
        e.getLocalizedMessage());
    } catch (final ClientExecutionTimeoutException e) {
      throw new SQLTimeoutException(
        Error.getErrorMessage(LOGGER, Error.QUERY_TIMED_OUT, this.queryId.get()),
        e);
    }
  }

  @Override
  public int executeUpdate(String sql) throws SQLException {
    verifyOpen();
    throw new SQLFeatureNotSupportedException(Error.lookup(Error.READ_ONLY));
  }

  @Override
  public int executeUpdate(String sql, int autoGeneratedKeys) throws SQLException {
    verifyOpen();
    throw new SQLFeatureNotSupportedException(Error.lookup(Error.READ_ONLY));
  }

  @Override
  public int executeUpdate(String sql, int[] columnIndexes) throws SQLException {
    verifyOpen();
    throw new SQLFeatureNotSupportedException(Error.lookup(Error.READ_ONLY));
  }

  @Override
  public int executeUpdate(String sql, String[] columnNames) throws SQLException {
    verifyOpen();
    throw new SQLFeatureNotSupportedException(Error.lookup(Error.READ_ONLY));
  }

  @Override
  public TimestreamConnection getConnection() throws SQLException {
    verifyOpen();
    return connection;
  }

  @Override
  public int getFetchDirection() throws SQLException {
    verifyOpen();
    return ResultSet.FETCH_FORWARD;
  }

  @Override
  public int getFetchSize() throws SQLException {
    verifyOpen();
    return fetchSize;
  }

  @Override
  public ResultSet getGeneratedKeys() throws SQLException {
    verifyOpen();
    throw new SQLFeatureNotSupportedException(Error.lookup(Error.UNSUPPORTED_GENERATED_KEYS));
  }

  @Override
  public long getLargeMaxRows() throws SQLException {
    verifyOpen();
    // Maximum result size is 1MB, so therefore a singe row cannot exceed this.
    return largeMaxRows;
  }

  @Override
  public long getLargeUpdateCount() throws SQLException {
    verifyOpen();

    // Updates are not supported, so always return -1.
    return -1;
  }

  @Override
  public int getMaxFieldSize() throws SQLException {
    verifyOpen();
    return maxFieldSize;
  }

  @Override
  public int getMaxRows() throws SQLException {
    final long maxRows = getLargeMaxRows();
    if (maxRows > Integer.MAX_VALUE) {
      final String warning = Warning.lookup(Warning.MAX_VALUE_TRUNCATED, maxRows, Integer.MAX_VALUE);
      LOGGER.warn(warning);
      this.addWarning(new SQLWarning(warning));
      return Integer.MAX_VALUE;
    }
    return (int) maxRows;
  }

  @Override
  public boolean getMoreResults() throws SQLException {
    return getMoreResults(Statement.CLOSE_CURRENT_RESULT);
  }

  @Override
  public boolean getMoreResults(int current) throws SQLException {
    verifyOpen();
    if ((Statement.KEEP_CURRENT_RESULT != current) && (this.resultSet != null)) {
      this.resultSet.close();
      this.resultSet = null;
    }
    return false;
  }

  @Override
  public int getQueryTimeout() throws SQLException {
    verifyOpen();
    return this.clientConfiguration.getClientExecutionTimeout() / Constants.NUM_MILLISECONDS_IN_SECOND;
  }

  @Override
  public ResultSet getResultSet() throws SQLException {
    verifyOpen();
    return resultSet;
  }

  @Override
  public int getResultSetConcurrency() throws SQLException {
    verifyOpen();
    return ResultSet.CONCUR_READ_ONLY;
  }

  @Override
  public int getResultSetHoldability() throws SQLException {
    verifyOpen();
    return ResultSet.CLOSE_CURSORS_AT_COMMIT;
  }

  @Override
  public int getResultSetType() throws SQLException {
    verifyOpen();
    return ResultSet.TYPE_FORWARD_ONLY;
  }

  @Override
  public int getUpdateCount() throws SQLException {
    return (int) this.getLargeUpdateCount();
  }

  @Override
  public SQLWarning getWarnings() throws SQLException {
    verifyOpen();
    return warnings;
  }

  @Override
  public boolean isClosed() {
    return isClosed.get();
  }

  @Override
  public boolean isCloseOnCompletion() throws SQLException {
    verifyOpen();
    return shouldCloseOnCompletion;
  }

  @Override
  public boolean isPoolable() throws SQLException {
    verifyOpen();
    // Statement pooling is not supported.
    return false;
  }

  @Override
  public boolean isWrapperFor(Class<?> iface) {
    return (null != iface) && iface.isAssignableFrom(this.getClass());
  }

  @Override
  public void setCursorName(String name) throws SQLException {
    verifyOpen();
    throw new SQLFeatureNotSupportedException(Error.lookup(Error.READ_ONLY));
  }

  @Override
  public void setEscapeProcessing(boolean enable) throws SQLException {
    verifyOpen();
    // Do nothing, because the driver does not support escape processing.
  }

  @Override
  public void setFetchDirection(int direction) throws SQLException {
    verifyOpen();
    if (direction != ResultSet.FETCH_FORWARD) {
      throw Error.createSQLException(LOGGER, Error.UNSUPPORTED_FETCH_DIRECTION, direction);
    }
  }

  @Override
  public void setFetchSize(int rows) throws SQLException {
    verifyOpen();
    if (rows < 1) {
      throw Error.createSQLException(LOGGER, Error.INVALID_FETCH_SIZE, rows);
    }

    // Silently truncate to the maximum number of rows that can be retrieved at a time.
    this.fetchSize = Math.min(rows, Constants.MAX_FETCH_SIZE);
  }

  @Override
  public void setLargeMaxRows(long max) throws SQLException {
    verifyOpen();
    if (max < 0) {
      throw Error.createSQLException(LOGGER, Error.INVALID_LARGE_MAX_ROWS_SIZE, max);
    }

    this.largeMaxRows = max;
  }

  @Override
  public void setMaxFieldSize(int max) throws SQLException {
    verifyOpen();

    if (max < 0) {
      throw Error.createSQLException(LOGGER, Error.INVALID_MAX_FIELD_SIZE, max);
    }

    this.maxFieldSize = max;
  }

  @Override
  public void setMaxRows(int max) throws SQLException {
    setLargeMaxRows(max);
  }

  @Override
  public void setPoolable(boolean poolable) throws SQLException {
    verifyOpen();
    throw new SQLFeatureNotSupportedException(Error.lookup(Error.POOLING_NOT_SUPPORTED));
  }

  @Override
  public void setQueryTimeout(int seconds) throws SQLException {
    verifyOpen();
    if (seconds < 0) {
      throw Error.createSQLException(LOGGER, Error.INVALID_TIMEOUT, seconds);
    }
    this.clientConfiguration.setClientExecutionTimeout(seconds * Constants.NUM_MILLISECONDS_IN_SECOND);
    this.queryClient = connection.getQueryClientBuilder()
        .withClientConfiguration(clientConfiguration)
        .build();
  }

  @Override
  public <T> T unwrap(Class<T> iface) throws SQLException {
    if (iface.isAssignableFrom(this.getClass())) {
      return iface.cast(this);
    }

    throw Error.createSQLException(LOGGER, Error.CANNOT_UNWRAP, iface.toString());
  }

  /**
   * Indicate that a child of this Statement has closed.
   *
   * @throws SQLException if there is an error closing the statement.
   */
  void childClose() throws SQLException {
    if (this.shouldCloseOnCompletion) {
      close();
    }
  }

  /**
   * Getter for the Timestream query client.
   *
   * @return The Timestream query client.
   */
  AmazonTimestreamQuery getClient() {
    return this.queryClient;
  }

  /**
   * Set that the current child result set is closed.
   */
  void setResultNoMoreRows() {
    this.queryId.set(null);
  }

  /**
   * Adds a new {@link SQLWarning} to the end of the warning list.
   *
   * @param warning the {@link SQLWarning} to add.
   */
  void addWarning(final SQLWarning warning) {
    if (this.warnings == null) {
      this.warnings = warning;
    } else {
      this.warnings.setNextWarning(warning);
    }
  }

  /**
   * Cancel the current statement, if any.
   */
  private void doCancel() {
    if ((this.queryId.get() == null) || !this.canCancel.get()) {
      LOGGER.debug("Query is not cancelable.");
      return;
    }

    try {
      LOGGER.debug("Sending a CancelQueryRequest for query ID: {}", this.queryId);
      this.getClient().cancelQuery(new CancelQueryRequest().withQueryId(this.queryId.get()));
      LOGGER.info(
        "Query ID: {} has been canceled.\n"
          + "Total execution time until interruption: {}ms\n"
          + "Total number of pages: {}\n"
          + "Number of empty pages: {}",
        this.queryId,
        this.totalExecutionTime,
        this.numPages,
        this.numEmptyPages);
    } catch (AmazonTimestreamQueryException e) {
      // Eat the exception if one occurs, as there's an unavoidable race condition where if we are waiting on
      // the response to the execute we can send a cancel, and Timestream knows the query has already finished.
      // In this case, Timestream will error in what we think is a valid scenario. Simply warn about this instead.

      final String warning = Warning.lookup(Warning.ERROR_CANCELING_QUERY, this.queryId.get(), e.getLocalizedMessage());
      LOGGER.warn(warning);
      this.addWarning(new SQLWarning(warning, e));
    }
  }

  /**
   * Verify the statement is open.
   *
   * @throws SQLException if the statement is closed.
   */
  protected void verifyOpen() throws SQLException {
    if (isClosed.get()) {
      throw Error.createSQLException(LOGGER, Error.STMT_CLOSED);
    }
  }

  /**
   * Retrieve query result.
   *
   * @param request The request that sent to retrieve result.
   * @return A {@link QueryResult} with query result.
   */
  private QueryResult retrieveResult(QueryRequest request) {
    final long startRetrievalTime = System.nanoTime();
    final QueryResult result = connection.getQueryClient().query(request);
    final long executionTime = TimeUnit.NANOSECONDS
        .toMillis(System.nanoTime() - startRetrievalTime);
    this.totalExecutionTime.addAndGet(executionTime);
    this.numPages.incrementAndGet();
    return result;
  }
}
